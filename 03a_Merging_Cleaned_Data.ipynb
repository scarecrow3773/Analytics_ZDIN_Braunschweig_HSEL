{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ae966f",
   "metadata": {},
   "source": [
    "# Merging der bereinigten Datensätze\n",
    "\n",
    "**Libraries**<br>\n",
    "pandas:     Datenverarbeitung<br>\n",
    "os:         Betriebsystem-Funktionen für relative Pfadreferenzierung<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80aea91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dirname = os.path.abspath('')\n",
    "\n",
    "df_path = os.path.join(dirname, '2019_Cleaned_Data_15min.csv')\n",
    "\n",
    "path_building1 = os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building1.csv')\n",
    "path_building2 = os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building2.csv')\n",
    "path_building3 = os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building3.csv')\n",
    "path_building4 = os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building4.csv')\n",
    "path_building5 = os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a336d2c",
   "metadata": {},
   "source": [
    "**10-minütigen Wettermessungen werden zu stündlichen zusammengefasst**<br>\n",
    "Die Wahl von sum() und mean() beim Resampling wird auf Basis der jeweiligen Messgröße getroffen.\n",
    "Basierend auf den timespamps \"MESS_DATUM\" werden die dataframes gemerged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1442910f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    MESS_DATUM  RWS_DAU_10  RWS_10  DS_10  GS_10  SD_10  \\\n",
      "0    2019-01-01 00:00:00+00:00        13.0    0.00    0.0    0.0    0.0   \n",
      "1    2019-01-01 01:00:00+00:00        35.0    0.03    0.0    0.0    0.0   \n",
      "2    2019-01-01 02:00:00+00:00        30.0    0.03    0.0    0.0    0.0   \n",
      "3    2019-01-01 03:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "4    2019-01-01 04:00:00+00:00         8.0    0.00    0.0    0.0    0.0   \n",
      "...                        ...         ...     ...    ...    ...    ...   \n",
      "8755 2019-12-31 19:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "8756 2019-12-31 20:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "8757 2019-12-31 21:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "8758 2019-12-31 22:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "8759 2019-12-31 23:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "\n",
      "         FF_10       DD_10        PP_10     TT_10    TM5_10      RF_10  \n",
      "0     5.400000  260.000000  1020.300000  7.700000  7.100000  90.100000  \n",
      "1     6.375000  265.000000  1019.725000  7.325000  6.850000  92.000000  \n",
      "2     6.940000  264.000000  1018.660000  7.300000  6.740000  89.360000  \n",
      "3     6.400000  260.000000  1017.650000  7.466667  6.733333  82.666667  \n",
      "4     7.525000  260.000000  1016.775000  7.450000  6.675000  81.425000  \n",
      "...        ...         ...          ...       ...       ...        ...  \n",
      "8755  2.000000  265.000000  1028.083333  3.800000 -0.166667  84.966667  \n",
      "8756  1.933333  271.666667  1028.133333  2.500000 -1.583333  92.133333  \n",
      "8757  1.733333  271.666667  1028.083333  2.616667 -1.516667  96.300000  \n",
      "8758  1.383333  255.000000  1028.250000  1.900000 -2.316667  97.350000  \n",
      "8759  1.366667  265.000000  1028.383333 -0.333333 -3.066667  98.933333  \n",
      "\n",
      "[8760 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = pd.read_csv(df_path)\n",
    "\n",
    "# Define a custom aggregation dictionary for each column\n",
    "aggregation_dict = {\n",
    "    'RWS_DAU_10':   'sum',      # Regendauer (10-min Messungen)\n",
    "    'RWS_10':       'sum',      # Regenmenge (Höhe in mm, 10-min Messungen)\n",
    "    'DS_10':        'sum',      # Diffuse Strahlung (10-min Messungen)\n",
    "    'GS_10':        'sum',      # Globale Strahlung (10-min Messungen)\n",
    "    'SD_10':        'sum',      # Sonnenschein-Dauer (10-min Messungen)\n",
    "    'FF_10':        'mean',     # Durchschn. Windgeschwindigkeit\n",
    "    'DD_10':        'mean',     # Durchschn. Windrichtung\n",
    "    'PP_10':        'mean',     # Luftdruck auf Höhe der Messstation\n",
    "    'TT_10':        'mean',     # Lufttemperatur 2 m über dem Boden\n",
    "    'TM5_10':       'mean',     # Lufttemperatur 5 cm über dem Boden\n",
    "    'RF_10':        'mean'      # Relative Luftfeuchtigkeit\n",
    "}\n",
    "\n",
    "# Convert the 'MESS_DATUM' column to datetime if it's not already\n",
    "cleaned_df['MESS_DATUM'] = pd.to_datetime(cleaned_df['MESS_DATUM'], utc=True)\n",
    "# Set the 'rec_time' column as the index\n",
    "cleaned_df.set_index('MESS_DATUM', inplace=True)\n",
    "\n",
    "# Apply the aggregation using the agg method\n",
    "cleaned_df = cleaned_df.resample('1h').agg(aggregation_dict)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "cleaned_df = cleaned_df.reset_index()\n",
    "print(cleaned_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d83f99",
   "metadata": {},
   "source": [
    "**Merging der Haushaltslasten und Verkettung mit den Wetterdaten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "899e3f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     MESS_DATUM  RWS_DAU_10  RWS_10  DS_10  GS_10  SD_10  \\\n",
      "0     2019-01-01 00:00:00+00:00        13.0    0.00    0.0    0.0    0.0   \n",
      "1     2019-01-01 01:00:00+00:00        35.0    0.03    0.0    0.0    0.0   \n",
      "2     2019-01-01 02:00:00+00:00        30.0    0.03    0.0    0.0    0.0   \n",
      "3     2019-01-01 03:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "4     2019-01-01 04:00:00+00:00         8.0    0.00    0.0    0.0    0.0   \n",
      "...                         ...         ...     ...    ...    ...    ...   \n",
      "43795 2019-12-31 19:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "43796 2019-12-31 20:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "43797 2019-12-31 21:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "43798 2019-12-31 22:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "43799 2019-12-31 23:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "\n",
      "          FF_10       DD_10        PP_10     TT_10    TM5_10      RF_10  \\\n",
      "0      5.400000  260.000000  1020.300000  7.700000  7.100000  90.100000   \n",
      "1      6.375000  265.000000  1019.725000  7.325000  6.850000  92.000000   \n",
      "2      6.940000  264.000000  1018.660000  7.300000  6.740000  89.360000   \n",
      "3      6.400000  260.000000  1017.650000  7.466667  6.733333  82.666667   \n",
      "4      7.525000  260.000000  1016.775000  7.450000  6.675000  81.425000   \n",
      "...         ...         ...          ...       ...       ...        ...   \n",
      "43795  2.000000  265.000000  1028.083333  3.800000 -0.166667  84.966667   \n",
      "43796  1.933333  271.666667  1028.133333  2.500000 -1.583333  92.133333   \n",
      "43797  1.733333  271.666667  1028.083333  2.616667 -1.516667  96.300000   \n",
      "43798  1.383333  255.000000  1028.250000  1.900000 -2.316667  97.350000   \n",
      "43799  1.366667  265.000000  1028.383333 -0.333333 -3.066667  98.933333   \n",
      "\n",
      "             load  \n",
      "0      427.419835  \n",
      "1      591.964497  \n",
      "2      675.726043  \n",
      "3      704.449528  \n",
      "4      500.577103  \n",
      "...           ...  \n",
      "43795  781.530997  \n",
      "43796  645.084425  \n",
      "43797  641.858920  \n",
      "43798  577.216580  \n",
      "43799  327.084160  \n",
      "\n",
      "[43800 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "data_building1 = pd.read_csv(path_building1)\n",
    "data_building2 = pd.read_csv(path_building2)\n",
    "data_building3 = pd.read_csv(path_building3)\n",
    "data_building4 = pd.read_csv(path_building4)\n",
    "data_building5 = pd.read_csv(path_building5)\n",
    "\n",
    "data_building_list = [data_building1, data_building2, data_building3, data_building4, data_building5]\n",
    "\n",
    "# Loop through each data_building DataFrame\n",
    "for i, df in enumerate(data_building_list):\n",
    "    # Convert the 'rec_time' column to datetime if it's not already\n",
    "    df['rec_time'] = pd.to_datetime(df['rec_time'], utc=True)\n",
    "    # Set the 'rec_time' column as the index\n",
    "    df.set_index('rec_time', inplace=True)\n",
    "    df.index += pd.Timedelta(hours=1)\n",
    "    # Create a DatetimeIndex to enable resampling\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    # Resample the data to 1-hour intervals, maintaining the sum of each hour\n",
    "    df = df.resample('1h', origin='start').sum()\n",
    "    # Reset the index to turn the index into a regular column\n",
    "    df = df.reset_index()\n",
    "    data_building_list[i] = df\n",
    "\n",
    "data_building1 = pd.merge(cleaned_df, data_building_list[0], left_index=True, right_index=True)\n",
    "data_building2 = pd.merge(cleaned_df, data_building_list[1], left_index=True, right_index=True)\n",
    "data_building3 = pd.merge(cleaned_df, data_building_list[2], left_index=True, right_index=True)\n",
    "data_building4 = pd.merge(cleaned_df, data_building_list[3], left_index=True, right_index=True)\n",
    "data_building5 = pd.merge(cleaned_df, data_building_list[4], left_index=True, right_index=True)\n",
    "\n",
    "df = pd.concat([data_building1, data_building2, data_building3, data_building4, data_building5], ignore_index=True)\n",
    "\n",
    "df = df.drop('rec_time', axis=1)\n",
    "print(df)\n",
    "\n",
    "df.to_csv('2019_Merged_Clean_Data_1h.csv', index=False) #index=FALSE for not including row indices\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
