{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ae966f",
   "metadata": {},
   "source": [
    "# Initialisierung\n",
    "\n",
    "**Libraries**<br>\n",
    "pandas:     Datenverarbeitung<br>\n",
    "os:         Betriebsystem-Funktionen für relative Pfadreferenzierung<br>\n",
    "datetime:   Verarbeitung der Timstamps<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80aea91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dirname = os.path.abspath('')\n",
    "\n",
    "df_path = os.path.join(dirname, '2019_Cleaned_Data_15min.csv')\n",
    "\n",
    "path_building1 = os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building1.csv')\n",
    "path_building2 = os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building2.csv')\n",
    "path_building3 = os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building3.csv')\n",
    "path_building4 = os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building4.csv')\n",
    "path_building5 = os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a336d2c",
   "metadata": {},
   "source": [
    "**Merging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1442910f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       RWS_DAU_10  RWS_10  DS_10  GS_10  SD_10  FF_10  DD_10   PP_10  TT_10  \\\n",
      "0             8.0    0.00    0.0    0.0    0.0    4.4  260.0  1020.7    7.9   \n",
      "1             5.0    0.00    0.0    0.0    0.0    6.4  260.0  1019.9    7.5   \n",
      "2             9.0    0.00    0.0    0.0    0.0    6.4  270.0  1020.0    7.4   \n",
      "3             9.0    0.03    0.0    0.0    0.0    7.0  270.0  1019.8    7.3   \n",
      "4             8.0    0.00    0.0    0.0    0.0    6.4  260.0  1019.6    7.3   \n",
      "...           ...     ...    ...    ...    ...    ...    ...     ...    ...   \n",
      "48329         0.0    0.00    0.0    0.0    0.0    0.9  240.0  1028.3   -0.4   \n",
      "48330         0.0    0.00    0.0    0.0    0.0    1.1  270.0  1028.4   -0.7   \n",
      "48331         0.0    0.00    0.0    0.0    0.0    1.5  290.0  1028.6   -0.8   \n",
      "48332         0.0    0.00    0.0    0.0    0.0    1.9  290.0  1028.4   -0.2   \n",
      "48333         0.0    0.00    0.0    0.0    0.0    1.6  260.0  1028.3    0.1   \n",
      "\n",
      "       TM5_10  RF_10                 MESS_DATUM  \n",
      "0         7.2   88.1  2019-01-01 00:00:00+00:00  \n",
      "1         7.0   92.1  2019-01-01 00:50:00+00:00  \n",
      "2         6.9   91.9  2019-01-01 01:00:00+00:00  \n",
      "3         6.9   92.2  2019-01-01 01:10:00+00:00  \n",
      "4         6.8   92.0  2019-01-01 01:20:00+00:00  \n",
      "...       ...    ...                        ...  \n",
      "48329    -3.2   97.6  2019-12-31 23:10:00+00:00  \n",
      "48330    -3.2   98.9  2019-12-31 23:20:00+00:00  \n",
      "48331    -3.1  100.0  2019-12-31 23:30:00+00:00  \n",
      "48332    -2.9  100.0  2019-12-31 23:40:00+00:00  \n",
      "48333    -2.9  100.0  2019-12-31 23:50:00+00:00  \n",
      "\n",
      "[48334 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(df_path)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed1623ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           RWS_DAU_10  RWS_10  DS_10  GS_10  SD_10     FF_10  \\\n",
      "MESS_DATUM                                                                     \n",
      "2019-01-01 00:00:00+00:00        13.0    0.00    0.0    0.0    0.0  5.400000   \n",
      "2019-01-01 01:00:00+00:00        35.0    0.03    0.0    0.0    0.0  6.375000   \n",
      "2019-01-01 02:00:00+00:00        30.0    0.03    0.0    0.0    0.0  6.940000   \n",
      "2019-01-01 03:00:00+00:00         0.0    0.00    0.0    0.0    0.0  6.400000   \n",
      "2019-01-01 04:00:00+00:00         8.0    0.00    0.0    0.0    0.0  7.525000   \n",
      "...                               ...     ...    ...    ...    ...       ...   \n",
      "2019-12-31 19:00:00+00:00         0.0    0.00    0.0    0.0    0.0  2.000000   \n",
      "2019-12-31 20:00:00+00:00         0.0    0.00    0.0    0.0    0.0  1.933333   \n",
      "2019-12-31 21:00:00+00:00         0.0    0.00    0.0    0.0    0.0  1.733333   \n",
      "2019-12-31 22:00:00+00:00         0.0    0.00    0.0    0.0    0.0  1.383333   \n",
      "2019-12-31 23:00:00+00:00         0.0    0.00    0.0    0.0    0.0  1.366667   \n",
      "\n",
      "                                DD_10        PP_10     TT_10    TM5_10  \\\n",
      "MESS_DATUM                                                               \n",
      "2019-01-01 00:00:00+00:00  260.000000  1020.300000  7.700000  7.100000   \n",
      "2019-01-01 01:00:00+00:00  265.000000  1019.725000  7.325000  6.850000   \n",
      "2019-01-01 02:00:00+00:00  264.000000  1018.660000  7.300000  6.740000   \n",
      "2019-01-01 03:00:00+00:00  260.000000  1017.650000  7.466667  6.733333   \n",
      "2019-01-01 04:00:00+00:00  260.000000  1016.775000  7.450000  6.675000   \n",
      "...                               ...          ...       ...       ...   \n",
      "2019-12-31 19:00:00+00:00  265.000000  1028.083333  3.800000 -0.166667   \n",
      "2019-12-31 20:00:00+00:00  271.666667  1028.133333  2.500000 -1.583333   \n",
      "2019-12-31 21:00:00+00:00  271.666667  1028.083333  2.616667 -1.516667   \n",
      "2019-12-31 22:00:00+00:00  255.000000  1028.250000  1.900000 -2.316667   \n",
      "2019-12-31 23:00:00+00:00  265.000000  1028.383333 -0.333333 -3.066667   \n",
      "\n",
      "                               RF_10  \n",
      "MESS_DATUM                            \n",
      "2019-01-01 00:00:00+00:00  90.100000  \n",
      "2019-01-01 01:00:00+00:00  92.000000  \n",
      "2019-01-01 02:00:00+00:00  89.360000  \n",
      "2019-01-01 03:00:00+00:00  82.666667  \n",
      "2019-01-01 04:00:00+00:00  81.425000  \n",
      "...                              ...  \n",
      "2019-12-31 19:00:00+00:00  84.966667  \n",
      "2019-12-31 20:00:00+00:00  92.133333  \n",
      "2019-12-31 21:00:00+00:00  96.300000  \n",
      "2019-12-31 22:00:00+00:00  97.350000  \n",
      "2019-12-31 23:00:00+00:00  98.933333  \n",
      "\n",
      "[8760 rows x 11 columns]\n",
      "                    MESS_DATUM  RWS_DAU_10  RWS_10  DS_10  GS_10  SD_10  \\\n",
      "0    2019-01-01 00:00:00+00:00        13.0    0.00    0.0    0.0    0.0   \n",
      "1    2019-01-01 01:00:00+00:00        35.0    0.03    0.0    0.0    0.0   \n",
      "2    2019-01-01 02:00:00+00:00        30.0    0.03    0.0    0.0    0.0   \n",
      "3    2019-01-01 03:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "4    2019-01-01 04:00:00+00:00         8.0    0.00    0.0    0.0    0.0   \n",
      "...                        ...         ...     ...    ...    ...    ...   \n",
      "8755 2019-12-31 19:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "8756 2019-12-31 20:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "8757 2019-12-31 21:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "8758 2019-12-31 22:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "8759 2019-12-31 23:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "\n",
      "         FF_10       DD_10        PP_10     TT_10    TM5_10      RF_10  \n",
      "0     5.400000  260.000000  1020.300000  7.700000  7.100000  90.100000  \n",
      "1     6.375000  265.000000  1019.725000  7.325000  6.850000  92.000000  \n",
      "2     6.940000  264.000000  1018.660000  7.300000  6.740000  89.360000  \n",
      "3     6.400000  260.000000  1017.650000  7.466667  6.733333  82.666667  \n",
      "4     7.525000  260.000000  1016.775000  7.450000  6.675000  81.425000  \n",
      "...        ...         ...          ...       ...       ...        ...  \n",
      "8755  2.000000  265.000000  1028.083333  3.800000 -0.166667  84.966667  \n",
      "8756  1.933333  271.666667  1028.133333  2.500000 -1.583333  92.133333  \n",
      "8757  1.733333  271.666667  1028.083333  2.616667 -1.516667  96.300000  \n",
      "8758  1.383333  255.000000  1028.250000  1.900000 -2.316667  97.350000  \n",
      "8759  1.366667  265.000000  1028.383333 -0.333333 -3.066667  98.933333  \n",
      "\n",
      "[8760 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a custom aggregation dictionary for each column\n",
    "aggregation_dict = {\n",
    "    'RWS_DAU_10':   'sum',      # Regendauer (10-min Messungen)\n",
    "    'RWS_10':       'sum',      # Regenmenge (Höhe in mm, 10-min Messungen)\n",
    "    'DS_10':        'sum',      # Diffuse Strahlung (10-min Messungen)\n",
    "    'GS_10':        'sum',      # Globale Strahlung (10-min Messungen)\n",
    "    'SD_10':        'sum',      # Sonnenschein-Dauer (10-min Messungen)\n",
    "    'FF_10':        'mean',     # Durchschn. Windgeschwindigkeit\n",
    "    'DD_10':        'mean',     # Durchschn. Windrichtung\n",
    "    'PP_10':        'mean',     # Luftdruck auf Höhe der Messstation\n",
    "    'TT_10':        'mean',     # Lufttemperatur 2 m über dem Boden\n",
    "    'TM5_10':       'mean',     # Lufttemperatur 5 cm über dem Boden\n",
    "    'RF_10':        'mean'      # Relative Luftfeuchtigkeit\n",
    "}\n",
    "\n",
    "# Convert the 'rec_time' column to datetime if it's not already\n",
    "df['MESS_DATUM'] = pd.to_datetime(df['MESS_DATUM'], utc=True)\n",
    "# Set the 'rec_time' column as the index\n",
    "df.set_index('MESS_DATUM', inplace=True)\n",
    "\n",
    "# Apply the aggregation using the agg method\n",
    "saved_df = df.resample('1H').agg(aggregation_dict)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(saved_df)\n",
    "saved_df = saved_df.reset_index()\n",
    "print(saved_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d83f99",
   "metadata": {},
   "source": [
    "**Haushaltslasten mergen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "899e3f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     MESS_DATUM  RWS_DAU_10  RWS_10  DS_10  GS_10  SD_10  \\\n",
      "0     2019-01-01 00:00:00+00:00        13.0    0.00    0.0    0.0    0.0   \n",
      "1     2019-01-01 01:00:00+00:00        35.0    0.03    0.0    0.0    0.0   \n",
      "2     2019-01-01 02:00:00+00:00        30.0    0.03    0.0    0.0    0.0   \n",
      "3     2019-01-01 03:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "4     2019-01-01 04:00:00+00:00         8.0    0.00    0.0    0.0    0.0   \n",
      "...                         ...         ...     ...    ...    ...    ...   \n",
      "43795 2019-12-31 19:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "43796 2019-12-31 20:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "43797 2019-12-31 21:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "43798 2019-12-31 22:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "43799 2019-12-31 23:00:00+00:00         0.0    0.00    0.0    0.0    0.0   \n",
      "\n",
      "          FF_10       DD_10        PP_10     TT_10    TM5_10      RF_10  \\\n",
      "0      5.400000  260.000000  1020.300000  7.700000  7.100000  90.100000   \n",
      "1      6.375000  265.000000  1019.725000  7.325000  6.850000  92.000000   \n",
      "2      6.940000  264.000000  1018.660000  7.300000  6.740000  89.360000   \n",
      "3      6.400000  260.000000  1017.650000  7.466667  6.733333  82.666667   \n",
      "4      7.525000  260.000000  1016.775000  7.450000  6.675000  81.425000   \n",
      "...         ...         ...          ...       ...       ...        ...   \n",
      "43795  2.000000  265.000000  1028.083333  3.800000 -0.166667  84.966667   \n",
      "43796  1.933333  271.666667  1028.133333  2.500000 -1.583333  92.133333   \n",
      "43797  1.733333  271.666667  1028.083333  2.616667 -1.516667  96.300000   \n",
      "43798  1.383333  255.000000  1028.250000  1.900000 -2.316667  97.350000   \n",
      "43799  1.366667  265.000000  1028.383333 -0.333333 -3.066667  98.933333   \n",
      "\n",
      "             load  \n",
      "0      427.419835  \n",
      "1      591.964497  \n",
      "2      675.726043  \n",
      "3      704.449528  \n",
      "4      500.577103  \n",
      "...           ...  \n",
      "43795  781.530997  \n",
      "43796  645.084425  \n",
      "43797  641.858920  \n",
      "43798  577.216580  \n",
      "43799  327.084160  \n",
      "\n",
      "[43800 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "data_building1 = pd.read_csv(path_building1)\n",
    "data_building2 = pd.read_csv(path_building2)\n",
    "data_building3 = pd.read_csv(path_building3)\n",
    "data_building4 = pd.read_csv(path_building4)\n",
    "data_building5 = pd.read_csv(path_building5)\n",
    "\n",
    "data_building_list = [data_building1, data_building2, data_building3, data_building4, data_building5]\n",
    "# Loop through each data_building DataFrame\n",
    "for i, df in enumerate(data_building_list):\n",
    "    # Convert the 'rec_time' column to datetime if it's not already\n",
    "    df['rec_time'] = pd.to_datetime(df['rec_time'], utc=True)\n",
    "    # Set the 'rec_time' column as the index\n",
    "    df.set_index('rec_time', inplace=True)\n",
    "    df.index += pd.Timedelta(hours=1)\n",
    "    # Create a DatetimeIndex to enable resampling\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    # Resample the data to 1-hour intervals, maintaining the sum of each hour\n",
    "    df = df.resample('1H', origin='start').sum()\n",
    "    # Reset the index to turn the index into a regular column\n",
    "    df = df.reset_index()\n",
    "    data_building_list[i] = df\n",
    "\n",
    "\n",
    "data_building1 = pd.merge(saved_df, data_building_list[0], left_index=True, right_index=True)\n",
    "data_building2 = pd.merge(saved_df, data_building_list[1], left_index=True, right_index=True)\n",
    "data_building3 = pd.merge(saved_df, data_building_list[2], left_index=True, right_index=True)\n",
    "data_building4 = pd.merge(saved_df, data_building_list[3], left_index=True, right_index=True)\n",
    "data_building5 = pd.merge(saved_df, data_building_list[4], left_index=True, right_index=True)\n",
    "\n",
    "df = pd.concat([data_building1, data_building2, data_building3, data_building4, data_building5], ignore_index=True)\n",
    "\n",
    "df = df.drop('rec_time', axis=1)\n",
    "print(df)\n",
    "\n",
    "df.to_csv('2019_Merged_Clean_Data_1h.csv', index=False) #index=FALSE for not including row indices\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
