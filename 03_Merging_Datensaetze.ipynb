{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging der unbereinigten Datensätze\n",
    "\n",
    "**Libraries**<br>\n",
    "pandas:     Datenverarbeitung<br>\n",
    "os:         Betriebsystem-Funktionen für relative Pfadreferenzierung<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dateipfade**<br>\n",
    "Wetterdaten Braunschweig<br>\n",
    "Haushaltslasten Braunschweig<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = os.path.abspath('')\n",
    "\n",
    "path_precipitation =    os.path.join(dirname, '2019_Braunschweig_Niederschlag_15min_UTC.csv')\n",
    "path_solar =            os.path.join(dirname, '2019_Braunschweig_Solar_15min_UTC.csv')\n",
    "path_wind =             os.path.join(dirname, '2019_Braunschweig_Wind_15min_UTC.csv')\n",
    "path_air =              os.path.join(dirname, '2019_Braunschweig_Luft_15min_UTC.csv')\n",
    "\n",
    "path_building1 =        os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building1.csv')\n",
    "path_building2 =        os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building2.csv')\n",
    "path_building3 =        os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building3.csv')\n",
    "path_building4 =        os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building4.csv')\n",
    "path_building5 =        os.path.join(dirname, 'Rohdaten_Last_Braunschweig\\Building5.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Einlesen und Merging der Wetterdaten (Predictors)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_precipitation =    pd.read_csv(path_precipitation)\n",
    "data_solar =            pd.read_csv(path_solar)\n",
    "data_wind =             pd.read_csv(path_wind)\n",
    "data_air =              pd.read_csv(path_air)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging der Wetterdaten**<br>\n",
    "Die einzelnen dataframes werden auf Basis der timestamps (MESS_DATUM) zusammengefasst. Dafür werden die strings der MESS_DATUM-Spalte in ein Datum konvertiert. Der Parameter utc=True fügt dem Datum einen Zeitzonenstempel hinzu (+00:00, default), dieser wird später für für das Merging in Stundenwerte benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     MESS_DATUM  RWS_DAU_10  RWS_10  DS_10  GS_10  SD_10  \\\n",
      "0     2019-01-01 00:00:00+00:00           8    0.00    0.0    0.0    0.0   \n",
      "1     2019-01-01 00:10:00+00:00          10    0.00    0.0    0.0    0.0   \n",
      "2     2019-01-01 00:20:00+00:00          10    0.00    0.0    0.0    0.0   \n",
      "3     2019-01-01 00:30:00+00:00          10    0.03    0.0    0.0    0.0   \n",
      "4     2019-01-01 00:40:00+00:00          10    0.01    0.0    0.0    0.0   \n",
      "...                         ...         ...     ...    ...    ...    ...   \n",
      "52555 2019-12-31 23:10:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "52556 2019-12-31 23:20:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "52557 2019-12-31 23:30:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "52558 2019-12-31 23:40:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "52559 2019-12-31 23:50:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "\n",
      "       FF_10  DD_10   PP_10  TT_10  TM5_10  RF_10  \n",
      "0        4.4    260  1020.7    7.9     7.2   88.1  \n",
      "1        5.8    270  1020.5    7.7     7.1   89.7  \n",
      "2        5.3    260  1020.4    7.5     7.1   93.0  \n",
      "3        5.1    260  1020.2    7.5     7.1   93.1  \n",
      "4        5.5    270  1020.2    7.5     7.1   92.9  \n",
      "...      ...    ...     ...    ...     ...    ...  \n",
      "52555    0.9    240  1028.3   -0.4    -3.2   97.6  \n",
      "52556    1.1    270  1028.4   -0.7    -3.2   98.9  \n",
      "52557    1.5    290  1028.6   -0.8    -3.1  100.0  \n",
      "52558    1.9    290  1028.4   -0.2    -2.9  100.0  \n",
      "52559    1.6    260  1028.3    0.1    -2.9  100.0  \n",
      "\n",
      "[52560 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Liste der dataframes\n",
    "dfs_list = [data_precipitation, data_solar, data_wind, data_air]\n",
    "\n",
    "# 'timestamp' Konvertierung\n",
    "for i, df in enumerate(dfs_list):\n",
    "    dfs_list[i]['MESS_DATUM'] = pd.to_datetime(df['MESS_DATUM'], utc=True)\n",
    "\n",
    "# Merging auf Basis des timestamps\n",
    "merged_df = dfs_list[0]\n",
    "for i in range(1, len(dfs_list)):\n",
    "    merged_df = pd.merge_asof(merged_df, dfs_list[i], on='MESS_DATUM')\n",
    "\n",
    "merged_df.to_csv('2019_Merged_Data_15min.csv', index=False) #index=FALSE for not including row indices\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10-minütigen Wettermessungen werden zu stündlichen zusammengefasst**<br>\n",
    "Die Wahl von sum() und mean() beim Resampling wird auf Basis der jeweiligen Messgröße getroffen.\n",
    "Basierend auf den timespamps \"MESS_DATUM\" werden die dataframes gemerged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    MESS_DATUM  RWS_DAU_10  RWS_10  DS_10  GS_10  SD_10  \\\n",
      "0    2019-01-01 00:00:00+00:00          53    0.04    0.0    0.0    0.0   \n",
      "1    2019-01-01 01:00:00+00:00          55    0.03    0.0    0.0    0.0   \n",
      "2    2019-01-01 02:00:00+00:00          40    0.03    0.0    0.0    0.0   \n",
      "3    2019-01-01 03:00:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "4    2019-01-01 04:00:00+00:00          28    0.00    0.0    0.0    0.0   \n",
      "...                        ...         ...     ...    ...    ...    ...   \n",
      "8755 2019-12-31 19:00:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "8756 2019-12-31 20:00:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "8757 2019-12-31 21:00:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "8758 2019-12-31 22:00:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "8759 2019-12-31 23:00:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "\n",
      "         FF_10       DD_10        PP_10     TT_10    TM5_10      RF_10  \n",
      "0     5.416667  263.333333  1020.316667  7.600000  7.100000  91.483333  \n",
      "1     6.550000  263.333333  1019.516667  7.283333  6.800000  91.983333  \n",
      "2     6.750000  263.333333  1018.683333  7.283333  6.733333  89.700000  \n",
      "3     6.400000  260.000000  1017.650000  7.466667  6.733333  82.666667  \n",
      "4     7.350000  260.000000  1016.650000  7.350000  6.533333  82.500000  \n",
      "...        ...         ...          ...       ...       ...        ...  \n",
      "8755  2.000000  265.000000  1028.083333  3.800000 -0.166667  84.966667  \n",
      "8756  1.933333  271.666667  1028.133333  2.500000 -1.583333  92.133333  \n",
      "8757  1.733333  271.666667  1028.083333  2.616667 -1.516667  96.300000  \n",
      "8758  1.383333  255.000000  1028.250000  1.900000 -2.316667  97.350000  \n",
      "8759  1.366667  265.000000  1028.383333 -0.333333 -3.066667  98.933333  \n",
      "\n",
      "[8760 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Dictionary mit den Resampling-Funktionen je Messgröße\n",
    "aggregation_dict = {\n",
    "    'RWS_DAU_10':   'sum',      # Regendauer (10-min Messungen)\n",
    "    'RWS_10':       'sum',      # Regenmenge (Höhe in mm, 10-min Messungen)\n",
    "    'DS_10':        'sum',      # Diffuse Strahlung (10-min Messungen)\n",
    "    'GS_10':        'sum',      # Globale Strahlung (10-min Messungen)\n",
    "    'SD_10':        'sum',      # Sonnenschein-Dauer (10-min Messungen)\n",
    "    'FF_10':        'mean',     # Durchschn. Windgeschwindigkeit\n",
    "    'DD_10':        'mean',     # Durchschn. Windrichtung\n",
    "    'PP_10':        'mean',     # Luftdruck auf Höhe der Messstation\n",
    "    'TT_10':        'mean',     # Lufttemperatur 2 m über dem Boden\n",
    "    'TM5_10':       'mean',     # Lufttemperatur 5 cm über dem Boden\n",
    "    'RF_10':        'mean'      # Relative Luftfeuchtigkeit\n",
    "}\n",
    "\n",
    "# Resampling auf Basis des Dictionaries, resample-Funktion benötigt zusätzliche Indexierung\n",
    "merged_df.set_index('MESS_DATUM', inplace=True)\n",
    "merged_df = merged_df.resample('1h').agg(aggregation_dict)\n",
    "\n",
    "# Einfügen der Zeilenindexierung\n",
    "merged_df = merged_df.reset_index()\n",
    "\n",
    "# Print DataFrame\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**15-minütigen Messungen des Gebäudelast-Datensatzes werden auf stündliche Werte zusammengefasst.**<br>\n",
    "Addition der vier Messwerte innerhalb einer Stunde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_building1 = pd.read_csv(path_building1)\n",
    "data_building2 = pd.read_csv(path_building2)\n",
    "data_building3 = pd.read_csv(path_building3)\n",
    "data_building4 = pd.read_csv(path_building4)\n",
    "data_building5 = pd.read_csv(path_building5)\n",
    "\n",
    "data_building_list = [data_building1, data_building2, data_building3, data_building4, data_building5]\n",
    "# Loop through each data_building DataFrame\n",
    "for i, df in enumerate(data_building_list):\n",
    "    # Convert the 'rec_time' column to datetime if it's not already\n",
    "    df['rec_time'] = pd.to_datetime(df['rec_time'], utc=True)\n",
    "    # Set the 'rec_time' column as the index\n",
    "    df.set_index('rec_time', inplace=True)\n",
    "    df.index += pd.Timedelta(hours=1)\n",
    "    # Create a DatetimeIndex to enable resampling\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    # Resample the data to 1-hour intervals, maintaining the sum of each hour\n",
    "    df = df.resample('1h', origin='start').sum()\n",
    "    # Reset the index to turn the index into a regular column\n",
    "    df = df.reset_index()\n",
    "    data_building_list[i] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Merging der Wetter- und Haushaltslastdaten mit anschließender Verkettung**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     MESS_DATUM  RWS_DAU_10  RWS_10  DS_10  GS_10  SD_10  \\\n",
      "0     2019-01-01 00:00:00+00:00          53    0.04    0.0    0.0    0.0   \n",
      "1     2019-01-01 01:00:00+00:00          55    0.03    0.0    0.0    0.0   \n",
      "2     2019-01-01 02:00:00+00:00          40    0.03    0.0    0.0    0.0   \n",
      "3     2019-01-01 03:00:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "4     2019-01-01 04:00:00+00:00          28    0.00    0.0    0.0    0.0   \n",
      "...                         ...         ...     ...    ...    ...    ...   \n",
      "43795 2019-12-31 19:00:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "43796 2019-12-31 20:00:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "43797 2019-12-31 21:00:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "43798 2019-12-31 22:00:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "43799 2019-12-31 23:00:00+00:00           0    0.00    0.0    0.0    0.0   \n",
      "\n",
      "          FF_10       DD_10        PP_10     TT_10    TM5_10      RF_10  \\\n",
      "0      5.416667  263.333333  1020.316667  7.600000  7.100000  91.483333   \n",
      "1      6.550000  263.333333  1019.516667  7.283333  6.800000  91.983333   \n",
      "2      6.750000  263.333333  1018.683333  7.283333  6.733333  89.700000   \n",
      "3      6.400000  260.000000  1017.650000  7.466667  6.733333  82.666667   \n",
      "4      7.350000  260.000000  1016.650000  7.350000  6.533333  82.500000   \n",
      "...         ...         ...          ...       ...       ...        ...   \n",
      "43795  2.000000  265.000000  1028.083333  3.800000 -0.166667  84.966667   \n",
      "43796  1.933333  271.666667  1028.133333  2.500000 -1.583333  92.133333   \n",
      "43797  1.733333  271.666667  1028.083333  2.616667 -1.516667  96.300000   \n",
      "43798  1.383333  255.000000  1028.250000  1.900000 -2.316667  97.350000   \n",
      "43799  1.366667  265.000000  1028.383333 -0.333333 -3.066667  98.933333   \n",
      "\n",
      "             load  \n",
      "0      427.419835  \n",
      "1      591.964497  \n",
      "2      675.726043  \n",
      "3      704.449528  \n",
      "4      500.577103  \n",
      "...           ...  \n",
      "43795  781.530997  \n",
      "43796  645.084425  \n",
      "43797  641.858920  \n",
      "43798  577.216580  \n",
      "43799  327.084160  \n",
      "\n",
      "[43800 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "data_building1 = pd.merge(merged_df, data_building_list[0], left_index=True, right_index=True)\n",
    "data_building2 = pd.merge(merged_df, data_building_list[1], left_index=True, right_index=True)\n",
    "data_building3 = pd.merge(merged_df, data_building_list[2], left_index=True, right_index=True)\n",
    "data_building4 = pd.merge(merged_df, data_building_list[3], left_index=True, right_index=True)\n",
    "data_building5 = pd.merge(merged_df, data_building_list[4], left_index=True, right_index=True)\n",
    "\n",
    "df = pd.concat([data_building1, data_building2, data_building3, data_building4, data_building5], ignore_index=True)\n",
    "\n",
    "# 'rec_time' wird nicht mehr benötigt, da die Wetterdaten mit 'MESS_DATUM' einen timestamp mitbringen\n",
    "df = df.drop('rec_time', axis=1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv('2019_Merged_Data_1h.csv', index=False) #index=FALSE for not including row indices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
